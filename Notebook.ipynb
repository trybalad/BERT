{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPtc9Nec3oUAdv5ZPaxlSmi",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/trybalad/BERT/blob/master/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pl_core_news_lg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Jeśli szkolimy z gpu\n",
    "!pip install tensorflow-gpu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Jeśli wykorzystujemy cpu\n",
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-cfaHvvMojqQ",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "from keras_bert.data_generator import DataGenerator\n",
    "from keras_bert.model import create_model\n",
    "from keras_bert.tokenizer import Tokenizer\n",
    "from keras_bert.training import train_model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Reading vocab.\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.read_vocab('./data/counted_vocab.txt')\n",
    "tokenizer.change_to_reversible()\n",
    "print(\"Vocab of size:\", tokenizer.vocab_size, \"loaded.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "embedding_dim = 512\n",
    "ff_dim = 512\n",
    "heads = 4\n",
    "encoder_num = 4\n",
    "\n",
    "checkpoint_file_path = \"./data/checkpoint_notebook.ckpt\"\n",
    "load_checkpoint = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#creating data generator\n",
    "data_generator = DataGenerator(\"./data/corpus_clean.txt\", max_len, tokenizer, batch_size=64, create_nsr_output=True)\n",
    "print(\"Data generator prepared.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#preparing model\n",
    "sequence_encoder = create_model(tokenizer.vocab_size, max_len, embedding_dim, encoder_num, heads, encoder_num)\n",
    "print(\"Model created.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start training.\n",
    "train = train_model(sequence_encoder, max_len, tokenizer, data_generator, epochs=100,\n",
    "                    checkpoint_file_path=checkpoint_file_path, load_checkpoint=load_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras_bert.prepare_data import create_tokens, create_masks, create_ids, create_segments, translate_ids, \\\n",
    "    create_pretrain_data\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "message = \"Pojęcie w programowaniu obiektowym najczyściej utożsamiane z klasą. Jest modelem, który w rzeczywistości nie reprezentuje żadnego istniejącego obiektu, a jedynie na podstawie którego definiowane są inne obiekty.\"\n",
    "tokens = create_tokens([message], tokenizer, max_len)\n",
    "mask_t = create_pretrain_data(tokens, tokenizer)\n",
    "ids = create_ids(mask_t, max_len, tokenizer)\n",
    "mask = create_masks(mask_t, max_len)\n",
    "segments = create_segments(mask_t, max_len)\n",
    "\n",
    "result = model.predict(x = [np.array(ids), np.array(segments), np.array(mask)])\n",
    "print(tokens)\n",
    "print(mask_t)\n",
    "print(ids)\n",
    "print(translate_ids(result, tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}